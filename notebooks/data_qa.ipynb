{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ea18ce-a03d-49a0-a04d-3e14d79ab7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# use svg graphics, display inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "import ast\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "# basic scientific computing imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# ai\n",
    "from tqdm import tqdm\n",
    "from Bronco import bronco\n",
    "\n",
    "# hex colors for plotting\n",
    "SOFT_PURPLE = '#8565C4'\n",
    "SOFT_RED = '#C23F38'\n",
    "SOFT_GREEN = '#56B000'\n",
    "NEUTRAL_GREY = '#A9A9A9'\n",
    "\n",
    "# display config\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.rcParams['figure.figsize'] = 6, 4\n",
    "plt.style.use('ggplot')\n",
    "np.set_printoptions(suppress=True)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bebb5e-8573-4c1b-8660-09013756de3f",
   "metadata": {},
   "source": [
    "Insight structure:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'question': question, \n",
    "    'query': query, \n",
    "    'query_result': result, \n",
    "    'answer': answer\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0d2d9-fd1a-4ab4-9bc9-6874bb26ae08",
   "metadata": {},
   "source": [
    "# Load and clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b2a882-457d-47a6-9720-5089c16d9fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>home_planet</th>\n",
       "      <th>did_use_cryosleep</th>\n",
       "      <th>cabin</th>\n",
       "      <th>destination</th>\n",
       "      <th>age</th>\n",
       "      <th>is_vip_passenger</th>\n",
       "      <th>name</th>\n",
       "      <th>did_survive_trip</th>\n",
       "      <th>total_spent_dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>9014_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>1.000</td>\n",
       "      <td>B/293/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Nunkib Dishearly</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>8615_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1.000</td>\n",
       "      <td>G/1389/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>13.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Jarena Buckentry</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0358_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>1.000</td>\n",
       "      <td>G/50/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>50.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Ronna Connon</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id home_planet  did_use_cryosleep     cabin  destination  \\\n",
       "8441      9014_01      Europa              1.000   B/293/P  TRAPPIST-1e   \n",
       "8058      8615_02       Earth              1.000  G/1389/S  55 Cancri e   \n",
       "320       0358_01       Earth              1.000    G/50/S  TRAPPIST-1e   \n",
       "\n",
       "        age  is_vip_passenger              name  did_survive_trip  \\\n",
       "8441 29.000             0.000  Nunkib Dishearly             1.000   \n",
       "8058 13.000             0.000  Jarena Buckentry             1.000   \n",
       "320  50.000             0.000      Ronna Connon             1.000   \n",
       "\n",
       "      total_spent_dollars  \n",
       "8441                0.000  \n",
       "8058                0.000  \n",
       "320                 0.000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    pd.read_csv('data/spaceship_titanic.csv')\n",
    "    .dropna(how='any')\n",
    "    .rename(columns=str.lower)\n",
    "    .rename(columns={\n",
    "        'passengerid': 'passenger_id',\n",
    "        'homeplanet': 'home_planet',\n",
    "        'cryosleep': 'did_use_cryosleep',\n",
    "        'vip': 'is_vip_passenger',\n",
    "        'transported': 'did_survive_trip'\n",
    "    })\n",
    "    .astype({\n",
    "        'did_survive_trip': float,\n",
    "        'did_use_cryosleep': float,\n",
    "        'is_vip_passenger': float\n",
    "    })\n",
    "    .assign(\n",
    "        total_spent_dollars=lambda d: d.roomservice + d.foodcourt + d.shoppingmall + d.spa + d.vrdeck\n",
    "    )\n",
    "    .drop(columns=['roomservice', 'foodcourt', 'shoppingmall', 'spa', 'vrdeck'])\n",
    "\n",
    ")\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3b767-7e61-4a91-ab71-9de92f216de4",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756b5f58-3bf2-4595-87ea-d3a8c548123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_to_query_prompt = '''\n",
    "# Context\n",
    "Your job is to write a sql query that answers the following question:\n",
    "{question}\n",
    "\n",
    "Below is a list of columns and sample values. Your query should only use the data contained in the table. The table name is `{table_name}`.\n",
    "\n",
    "# Columns and sample values\n",
    "{table_sample}\n",
    "\n",
    "If the question is not a question or is answerable with the given columns, respond to the best of your ability.\n",
    "Do not use columns that aren't in the table.\n",
    "Ensure that the query runs and returns the correct output.\n",
    "\n",
    "# Your query:\n",
    "'''\n",
    "\n",
    "def extract_first_sql_query(input_string):\n",
    "    pattern = r'(?:SELECT|WITH)(?:.|\\n)*?(?=;|$)'\n",
    "    query = re.search(pattern, input_string, flags=re.IGNORECASE)\n",
    "    \n",
    "    output_query = query.group(0) if query else None\n",
    "    \n",
    "    if output_query is None:\n",
    "        return None\n",
    "    return output_query + ';' if not output_query.endswith(';') else output_query\n",
    "\n",
    "def question_to_query(question: str, db_connection, table_name: str) -> str:\n",
    "    '''\n",
    "    Converts a natural language question into an SQL query based on a given table in a database.\n",
    "\n",
    "    This function takes a natural language question and converts it into an SQL query. It uses the `bronco` module\n",
    "    to interact with a machine learning model (GPT-4), which generates the SQL query based on the input question,\n",
    "    the name of the table, and a sample of data from the table.\n",
    "\n",
    "    Parameters:\n",
    "    question (str): A natural language question that is to be converted into an SQL query.\n",
    "    db_connection: A database connection object used to interact with the database.\n",
    "    table_name (str): The name of the table in the database to be queried.\n",
    "\n",
    "    Returns:\n",
    "    str: An SQL query string generated from the input question.\n",
    "    '''\n",
    "\n",
    "    table_sample = bronco.data.get_table_sample(db_connection, table_name)\n",
    "    query_generator = bronco.LLMFunction(\n",
    "        prompt_template=question_to_query_prompt,\n",
    "        model_name=bronco.GPT_4,\n",
    "        parser=extract_first_sql_query\n",
    "    )\n",
    "\n",
    "    return query_generator.generate({\n",
    "        'question': question,\n",
    "        'table_name': table_name,\n",
    "        'table_sample': table_sample\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a68ce0-2f56-4f86-aca1-a85fc460bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_answer_prompt = '''\n",
    "# Task\n",
    "Based on the results of a SQL query, provide a brief summary of the key findings and explicitly answer the following question:\n",
    "{question}\n",
    "\n",
    "The query results from the table `{table_name}` are as follows:\n",
    "\n",
    "# Query Results Table\n",
    "{query_results_table}\n",
    "\n",
    "In 2-5 sentences, summarize the main insights from the query results and give a clear and direct answer to the original question.\n",
    "\n",
    "# Summary and Answer:\n",
    "'''\n",
    "\n",
    "def interpret_query_results(question, query_result):\n",
    "\n",
    "    result_interpreter = bronco.LLMFunction(\n",
    "        prompt_template=results_to_answer_prompt,\n",
    "        model_name=bronco.GPT_4\n",
    "    )\n",
    "\n",
    "    return result_interpreter.generate({\n",
    "        'question': question,\n",
    "        'table_name': table_name,\n",
    "        'query_results_table': query_result\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34eed1bf-c889-4713-86d3-ac1b1a9c97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_insight(question: str, df: pd.DataFrame, table_name: str) -> Dict[str, Any]:\n",
    "    '''\n",
    "    Generates insights from a given question by querying a DataFrame.\n",
    "\n",
    "    This function takes a question as input, uploads a DataFrame to a sqlite3 in-memory\n",
    "    database under a specified table name, then generates a SQL query from the question.\n",
    "    It executes this query against the database, interprets the results, and returns an\n",
    "    insight in the form of a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    question (str): The question to be answered.\n",
    "    df (pd.DataFrame): The DataFrame to be queried.\n",
    "    table_name (str): The name of the table in the database. This should be meaningful\n",
    "                      as it helps the model understand the context of the data.\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, Any]: A dictionary containing the original question, generated SQL query,\n",
    "                    query results, and the interpreted answer.\n",
    "    '''\n",
    "    \n",
    "    db_connection = bronco.data.upload_df_to_sql(df, table_name)\n",
    "\n",
    "    query = question_to_query(\n",
    "        question=question,\n",
    "        db_connection=db_connection,\n",
    "        table_name=table_name\n",
    "    )\n",
    "\n",
    "    current_insight = {\n",
    "        'question': question,\n",
    "        'query': query\n",
    "    }\n",
    "    current_insight = maybe_fix_insight(current_insight)\n",
    "    \n",
    "    current_insight['query_result'] = bronco.data.query_database(db_connection, query)\n",
    "    db_connection.close()\n",
    "    \n",
    "    current_insight['answer'] = interpret_query_results(question, current_insight['query_result'])\n",
    "    insight = maybe_fix_insight(current_insight)\n",
    "    \n",
    "    return insight\n",
    "\n",
    "def pretty_print_insight(insight):\n",
    "    for key in insight:\n",
    "        print(f'{key}:\\n{insight[key]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2cf50c-5893-4b30-923f-103cdd148f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bad_insight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 47\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[1;32m     40\u001b[0m insight_fixer \u001b[38;5;241m=\u001b[39m bronco\u001b[38;5;241m.\u001b[39mLLMFunction(\n\u001b[1;32m     41\u001b[0m     prompt_template\u001b[38;5;241m=\u001b[39mfixer_prompt,\n\u001b[1;32m     42\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mbronco\u001b[38;5;241m.\u001b[39mGPT_3_5_TURBO,\n\u001b[1;32m     43\u001b[0m     parser\u001b[38;5;241m=\u001b[39mextract_dict\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m fix \u001b[38;5;241m=\u001b[39m insight_fixer\u001b[38;5;241m.\u001b[39mgenerate({\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsight_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: bad_insight,\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplanation\u001b[39m\u001b[38;5;124m'\u001b[39m: validation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     49\u001b[0m })\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(fix)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bad_insight' is not defined"
     ]
    }
   ],
   "source": [
    "fixer_prompt = '''\n",
    "# Context\n",
    "Your job is to find the error and fix it in a python dictionary that represents a data insight. It contains up to 4 elements: (question, query, query_result, answer). You will be given a brief explanation of what went wrong. Note that the `'query_result'` is never wrong, only the `'query'` or the `'answer'`\n",
    "\n",
    "# Task\n",
    "Return the fixed version of the dictionary. Return it in python dictionary form. Do not add extra key-value pairs.\n",
    "\n",
    "# Example output\n",
    "{{\n",
    "    'question': 'What are the top 3 countries in terms of user count?',\n",
    "    'query': 'SELECT country, COUNT(DISTINCT userid) AS total_users from users GROUP BY 1 ORDER BY 2 DESC LIMIT 3',\n",
    "    'query_result': \"     country  total_users\\n0        US       120000\\n1     Spain        95000\\n2    France        87000\",\n",
    "    'answer': 'The top 3 countries are US, Spain, France'\n",
    "}}\n",
    "\n",
    "# Incorrect dictionary\n",
    "{insight_dict}\n",
    "\n",
    "# Mistake explanation\n",
    "{explanation}\n",
    "\n",
    "# Your fixed insight dict\n",
    "'''\n",
    "\n",
    "def extract_dict(input_string):\n",
    "    pattern = r'\\{[^{}]*\\}'\n",
    "\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    if not match:\n",
    "        return {}\n",
    "\n",
    "    # Safely evaluate the matched string to a dictionary\n",
    "    try:\n",
    "        return ast.literal_eval(match.group(0))\n",
    "    except ValueError:\n",
    "        return {}\n",
    "\n",
    "\n",
    "insight_fixer = bronco.LLMFunction(\n",
    "    prompt_template=fixer_prompt,\n",
    "    model_name=bronco.GPT_3_5_TURBO,\n",
    "    parser=extract_dict\n",
    ")\n",
    "\n",
    "fix = insight_fixer.generate({\n",
    "    'insight_dict': bad_insight,\n",
    "    'explanation': validation['reasoning']\n",
    "})\n",
    "\n",
    "print(fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06da3d66-79d6-4648-8686-4bce2aaa6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_prompt = '''\n",
    "# Context\n",
    "You will be given a python dictionary that represents a data insight. It contains up to 4 elements: (question, query, query_result, answer). Your job is to validate these elements and ensure that there are no major errors. These errors can include SQL errors, incorrect interpretations of the data, SQL code that doesn't achieve the correct objective, etc. Note that the `'query_result'` is never wrong, only the `'query'` or the `'answer'`\n",
    "\n",
    "# Task\n",
    "Validate the following insight dictionary and return a decision of [VALID] or [NOT_VALID], followed by a brief explanation of why.\n",
    "\n",
    "# Example outputs\n",
    "[NOT_VALID] The SQL query performs integer division instead of float division for a proportion\n",
    "[VALID] There are no major issues\n",
    "[NOT_VALID] The answer incorrectly interprets the data and draws the wrong conclusion\n",
    "\n",
    "# Insight dictionary\n",
    "{insight_dict}\n",
    "\n",
    "# Your validation output\n",
    "'''\n",
    "\n",
    "def parse_label_with_regex(input_string):\n",
    "    # Using regex to extract both the label and the reasoning\n",
    "    match = re.search(r'\\[(.*?)\\]\\s*(.*)', input_string)\n",
    "\n",
    "    if not match:\n",
    "        return {}\n",
    "    return {\n",
    "        'label': match.group(1), \n",
    "        'reasoning': match.group(2)\n",
    "    }\n",
    "\n",
    "def maybe_fix_insight(insight):\n",
    "    \n",
    "    insight_validator = bronco.LLMFunction(\n",
    "        prompt_template=validator_prompt,\n",
    "        model_name=bronco.GPT_4,\n",
    "        parser=parse_label_with_regex\n",
    "    )\n",
    "    validation_result = insight_validator.generate({'insight_dict': insight})\n",
    "    \n",
    "    if validation_result['label'] == 'VALID':\n",
    "        return insight\n",
    "\n",
    "    print('Fixing insight...')\n",
    "\n",
    "    insight_fixer = bronco.LLMFunction(\n",
    "        prompt_template=fixer_prompt,\n",
    "        model_name=bronco.GPT_4,\n",
    "        parser=extract_dict\n",
    "    )\n",
    "\n",
    "    fixed_insight = insight_fixer.generate({\n",
    "        'insight_dict': insight,\n",
    "        'explanation': validation_result['reasoning']\n",
    "    })\n",
    "\n",
    "    original_keys = list(insight.keys())\n",
    "\n",
    "    # removes hallucinated keys\n",
    "    fixed_insight = {key: fixed_insight[key] for key in original_keys if key in fixed_insight}\n",
    "\n",
    "    return fixed_insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eadcc50-a735-49e0-b272-a59d72ef6d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing insight...\n",
      "question:\n",
      "What is the probability of surviving the trip by home planet?\n",
      "\n",
      "query:\n",
      "SELECT \n",
      "    home_planet, \n",
      "    SUM(did_survive_trip) AS survived, \n",
      "    COUNT(*) AS total, \n",
      "    (CAST(SUM(did_survive_trip) AS FLOAT) / CAST(COUNT(*) AS FLOAT)) AS survival_probability \n",
      "FROM \n",
      "    spaceship_titanic \n",
      "GROUP BY \n",
      "    home_planet;\n",
      "\n",
      "query_result:\n",
      "  home_planet  survived  total  survival_probability\n",
      "0       Earth  1518.000   3566                 0.426\n",
      "1      Europa  1104.000   1673                 0.660\n",
      "2        Mars   705.000   1367                 0.516\n",
      "\n",
      "answer:\n",
      "The probability of surviving the trip varies depending on the home planet of the passengers. Passengers from Europa have the highest survival probability at 66%, followed by Mars at 51.6%, and Earth at 42.6%. Therefore, the survival probability is highest for passengers from Europa and lowest for those from Earth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = 'What is the probability of surviving the trip by home planet?'\n",
    "table_name = 'spaceship_titanic'\n",
    "\n",
    "insight = question_to_insight(question, df, table_name)\n",
    "\n",
    "pretty_print_insight(insight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9543fd-f9d3-4513-aae6-9db11915529e",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "Write 2 functions:\n",
    "- An insight validator that ensures that there are no major flaws in the insight\n",
    "- An insight fixer. This function should pass the entire insight to an LLM and identify which step caused the error. Example: The SQL query divides two integers and returns 0 instead of a percentage. Have it return a dictionary with the fixed step. From there, run the subsequent steps with the messed up part fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3c24acb-4953-4863-86da-555282759db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "169582d3-22c0-4c92-b168-00f92a218a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_insight = copy.copy(insight)\n",
    "# good_insight = copy.copy(insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4fbc39ce-5f57-428c-83f5-92c588bc4f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NOT_VALID',\n",
       " 'reasoning': 'The SQL query performs integer division instead of float division for a probability calculation.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = insight_validator.generate({'insight_dict': bad_insight})\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2520eeb-6789-4d06-aff3-cef773f282bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the probability of surviving the trip by home planet?', 'query': 'SELECT \\n    COUNT(*) AS total_passengers,\\n    SUM(did_survive_trip) AS total_survived,\\n    CAST(SUM(did_survive_trip) AS FLOAT) / COUNT(*) AS probability_survival\\nFROM \\n    spaceship_titanic;', 'query_result': 'total_passengers  total_survived  probability_survival\\n0               1000             700               0.7', 'answer': 'The probability of surviving the trip by home planet is 0.7'}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
